# -*- coding: utf-8 -*-
"""anime-recommendationsystem

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/#fileId=https%3A//storage.googleapis.com/kaggle-colab-exported-notebooks/xazhurea/anime-recommendationsystem.9974ab64-f1a8-492b-bf2e-481c58c5ff17.ipynb%3FX-Goog-Algorithm%3DGOOG4-RSA-SHA256%26X-Goog-Credential%3Dgcp-kaggle-com%2540kaggle-161607.iam.gserviceaccount.com/20250613/auto/storage/goog4_request%26X-Goog-Date%3D20250613T034518Z%26X-Goog-Expires%3D259200%26X-Goog-SignedHeaders%3Dhost%26X-Goog-Signature%3D8c0d74e8b9afde590cc6da0d671dffd2d9f000d4006a8de682f1a327bdc1255425785d5375317776109f0b9d8a361fdb62b5a9c374f677cbe135dcbd98378aab1c0f65573077a0d9c698b2bcc8b826dcce0e66e646d2257a3fb35b6e2068a50956039bb7fbb6fcc912ab33a96a1419c3d9c32483a65f0daeeb618500dedde855cc7fdcccf412b0a546ad0e2a8e5e69fb59b1e538867e4f061558758874da373fef6680537d0831f43e911126c2e66f266cc9ed1d3149fb4f224cf212e8810c794dee33efcf8d12f1384fac5bc22f4a8cf9f9d83fbc7b9a6ab4186ca006dfd1757dcb49240bb1e17f1e171cdc031b13c9fb127e3ee42364234930ec6f5d983dc1

# **Recommendation System: Anime**
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import math
import seaborn as sns
sns.set(style='darkgrid',font_scale=1.5)
import plotly.express as px
import plotly.graph_objects as go
from plotly.subplots import make_subplots
from collections import Counter

#Data Preparation
from sklearn.preprocessing import LabelEncoder
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import train_test_split

# Modeling eval
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import cosine_similarity


import warnings
warnings.filterwarnings('ignore')

"""# Data Loading"""

import kagglehub

# Download latest version
path = kagglehub.dataset_download("CooperUnion/anime-recommendations-database")

print("Path to dataset files:", path)

# loding data
anime = pd.read_csv(path + '/anime.csv')
rating = pd.read_csv(path + '/rating.csv')

"""# Data Understanding

"""

# Membaca 5 baris data anime
anime.head()

# Membaca 5 baris data rating pengguna
rating.head()

print("Jumlah data judul anime:", len(anime.anime_id.unique()))
print("Jumlah data pengguna rating:", len(rating.user_id.unique()))

"""#Univariate Exploratory Data Analysis"""

anime.info()

rating.info()

print('\nJudul anime: ', anime.name.unique())
print('\nGenre anime: ', anime.genre.unique())
print('\nType anime: ', anime.type.unique())
print('\nEpisode anime: ', anime.episodes.unique())
print('\nRating anime: ', anime.rating.unique())
print('\nMembers anime: ', anime.members.unique())

"""Variabel-variabel pada Anime dataset adalah sebagai berikut:

**Dataset anime.csv**
- `anime_id` : ID unik untuk setiap anime di MyAnimeList
- `name` :Nama lengkap anime
- `genre` : Daftar genre (dipisahkan koma)
- `type` : Jenis anime (TV, Movie, OVA, dll)
- `episodes` : Jumlah episode
- `rating` : Rata-rata skor rating dari pengguna
- `members` : Jumlah anggota komunitas yang mengikuti anime ini

**Dataset rating.csv**
- `user_id` :	ID pengguna (anonim)
- `anime_id` :	ID anime yang dirating
- `rating` :	Nilai rating (1-10), -1 artinya ditonton tapi tidak diberi rating
"""

anime.describe()

rating.describe()

"""**Insight:**
- Rating tertinggi mencapai 10, dengan rata-rata sekitar 6.48.
- Median (50%) jumlah members adalah 1.552, menandakan sebagian besar anime memiliki basis penggemar yang relatif kecil, dan hanya sebagian kecil yang sangat populer.
- Ada nilai -1 pada kolom rating, yang umumnya menandakan bahwa user belum memberikan rating, hanya menambahkan anime ke daftar mereka
- Rata-rata rating yang diberikan user adalah 6.14, cukup sejalan dengan rata-rata rating dari dataset anime.


"""

import seaborn as sns
import matplotlib.pyplot as plt

plt.figure(figsize=(8, 5))
sns.countplot(data=anime, x='type', order=anime['type'].value_counts().index)
plt.title('Jumlah Anime per Tipe')
plt.xlabel('Tipe Anime')
plt.ylabel('Jumlah')
plt.xticks(rotation=45)
plt.tight_layout()
plt.show()

#versi tulisan

# Genre Anime

# Pisahkan dan hitung genre
genre_series = anime['genre'].dropna().str.split('|')
genre_counts = Counter([g for sublist in genre_series for g in sublist])
top_genres = dict(genre_counts.most_common(10))

plt.figure(figsize=(10, 6))
sns.barplot(x=list(top_genres.values()), y=list(top_genres.keys()))
plt.title('Top 10 Genre Anime')
plt.xlabel('Jumlah Anime')
plt.ylabel('Genre')
plt.tight_layout()
plt.show()

anime_populer = anime.sort_values(by='members', ascending=False).head(10)
anime_populer[['anime_id', 'name', 'type', 'members']]

plt.figure(figsize=(10, 6))
sns.barplot(data=anime_populer, y='name', x='members', palette='viridis')
plt.title('Top 10 Anime Paling Populer berdasarkan Jumlah Members')
plt.xlabel('Jumlah Members')
plt.ylabel('Judul Anime')
plt.tight_layout()
plt.show()

"""1. **Jumlah Anime per Tipe**

  Anime TV adalah tipe anime yang paling banyak diproduksi, disusul oleh OVA dan Movie. Ini menunjukkan bahwa TV series adalah format yang paling dominan, kemungkinan karena bisa menjangkau lebih banyak penonton dan menawarkan narasi yang panjang.

2. **Top 10 Genre Anime**
  
  Genre Hentai di posisi pertama, menunjukkan bahwa jumlah judul dalam genre ini sangat banyak. Kemudian disusul comedy, Music, dan Kids.

3. **Top 10 Anime Paling Populer**

  Death Note adalah anime dengan jumlah anggota (members) terbanyak. Anime populer lainnya seperti Attack on Titan (Shingeki no Kyojin), Sword Art Online, dan Fullmetal Alchemist: Brotherhood juga masuk dalam daftar, mencerminkan bahwa anime bergenre aksi, fantasi, dan psikologis memiliki daya tarik besar.


**🔍 Kesimpulan Umum:**

- TV series mendominasi produksi anime, tetapi OVA dan film juga tetap signifikan.
- Genre dan sub-genre yang sangat bervariasi menunjukkan fleksibilitas medium anime dalam menjangkau berbagai demografik.
- Popularitas anime tidak selalu berbanding lurus dengan jumlah genre atau tipe, melainkan dipengaruhi oleh kualitas cerita, daya tarik karakter, dan eksposur global.
"""

# Jumlah anime unik di anime.csv
print('Banyak anime di anime.csv:', len(anime.anime_id.unique()))

# Jumlah anime unik di rating.csv
print('Banyak anime di rating.csv:', len(rating.anime_id.unique()))

# Jumlah members (user count per anime) dari anime.csv
print('Banyak members di anime.csv:', len(anime.members.unique()))

# Jumlah user unik di rating.csv
print('Banyak user di rating.csv:', len(rating.user_id.unique()))

"""Jumlah anime di anime.csv lebih banyak daripada di rating.csv:

Tidak semua anime di database anime.csv memiliki rating dari user. Bisa jadi anime tersebut kurang populer atau belum dirating sama sekali oleh pengguna.
"""

# Cek missing value
anime.isnull().sum()

rating.isnull().sum()

"""# Data Preparation"""

#Menggabungkan dataset
anime_rating = pd.merge(anime,rating[["user_id","anime_id","rating"]], on = ["anime_id"],how = "right")
anime_rating.rename(columns = {'rating_x':'AverageRating','rating_y':'rating_user'}, inplace = True)

print("Final Dataset: ")
anime_rating.head()

anime_rating.shape

"""Penggabungan dataset dilakukan dengan cara right join menggunakan fungsi pd.merge() pada kolom anime_id, sehingga seluruh data dari rating.csv dipertahankan dan hanya informasi anime yang cocok dari anime.csv yang digabungkan. Dataset gabungan memiliki 9 kolom, yaitu: `anime_id`, `name`, `genre`, `type`, `episodes`, `AverageRating`, `members`, `user_id`, dan `rating_user`."""

anime_rating.isnull().sum()

#Lihat data yang punya mising value
anime_rating[anime_rating.isnull().any(axis=1)].head()

#Lihat missing value pada kolom type
anime_rating[anime_rating['type'].isnull()]

#Lihat missing value pada kolom episodes, name, member

anime_rating[anime_rating['episodes'].isnull() | anime_rating['name'].isnull() | anime_rating['members'].isnull()]

#Lihat missing value pada kolom episodes
anime_rating[anime_rating['AverageRating'].isnull()]

"""Karena terdapat banyak kolom dengan baris yang sama memiliki nilai kosong bersamaan pada kolom lain juga, maka penghapusan hanya berdasarkan `genre` dan `AverageRating` sudah cukup mewakili semua missing value untuk membersihkan baris-baris yang tidak lengkap, termasuk yang kolom lainnya yang kosong.


"""

# Menangani missing value genre anime_rating
anime_rating = anime_rating.dropna(subset=['genre', 'AverageRating'])
anime_rating.isnull().sum()

anime_rating.duplicated().sum()

# Hapus data duplikat
anime_rating = anime_rating.drop_duplicates()
anime_rating.duplicated().sum()

anime_rating.shape

# Mengubah value di rating (rating.csv) when = -1 diubah jadi 0
anime_rating.loc[anime_rating['rating_user'] == -1, 'rating_user'] = 0

anime_rating.head()

# Ambil hanya kolom relevan dan buang duplikat berdasarkan anime_id untuk model CBF
anime_unique = anime_rating[['anime_id', 'name', 'genre', 'AverageRating']].drop_duplicates('anime_id').copy()

# TF-IDF vectorizer: tokenisasi berdasarkan koma
tfidf = TfidfVectorizer(tokenizer=lambda x: x.split(', '))

# Melakukan perhitungan idf pada data cuisine
tfidf.fit(anime_unique['genre'])

# Mapping array dari fitur index integer ke fitur nama
tfidf.get_feature_names_out()

# Melakukan fit lalu ditransformasikan ke bentuk matrix
tfidf_matrix = tfidf.fit_transform(anime_unique['genre'])
print("Shape TF-IDF matrix:", tfidf_matrix.shape)

# Mengubah vektor tf-idf dalam bentuk matriks dengan fungsi todense()
tfidf_matrix.todense()

# Persiapan data untuk model CF
# Hanya ambil data dengan rating_user >= 5
print(f"Total data sebelum filter rating: {len(anime_rating)}")

filt_anime_rating = anime_rating[anime_rating['rating_user'] >= 7].copy()

print(f"Total data setelah filter rating: {len(filt_anime_rating)}")

import numpy as np
import tensorflow as tf
from tensorflow.keras import layers, Model, regularizers
import matplotlib.pyplot as plt


# Encode user_id dan anime_id
user_ids = filt_anime_rating['user_id'].unique().tolist()
user_to_user_encoded = {x: i for i, x in enumerate(user_ids)}
user_encoded_to_user = {i: x for i, x in enumerate(user_ids)}

anime_ids = filt_anime_rating['anime_id'].unique().tolist()
anime_to_anime_encoded = {x: i for i, x in enumerate(anime_ids)}
anime_encoded_to_anime = {i: x for i, x in enumerate(anime_ids)}

# Mapping ke dataframe
filt_anime_rating['user'] = filt_anime_rating['user_id'].map(user_to_user_encoded)
filt_anime_rating['anime'] = filt_anime_rating['anime_id'].map(anime_to_anime_encoded)

# Skala rating_user ke 0-1 supaya cocok sigmoid output
min_rating = filt_anime_rating['rating_user'].min()
max_rating = filt_anime_rating['rating_user'].max()
filt_anime_rating['rating'] = filt_anime_rating['rating_user'].apply(lambda x: (x - min_rating) / (max_rating - min_rating))

# Jumlah user dan anime
num_users = len(user_to_user_encoded)
num_anime = len(anime_to_anime_encoded)

# Split data train dan val
filt_anime_rating = filt_anime_rating.sample(frac=1, random_state=42)
train_size = int(0.8 * len(filt_anime_rating))

x = filt_anime_rating[['user', 'anime']].values
y = filt_anime_rating['rating'].values

x_train, x_val = x[:train_size], x[train_size:]
y_train, y_val = y[:train_size], y[train_size:]

"""# Modeling

## Model Development dengan Content Based Filtering
"""

# Membuat dataframe untuk melihat tf-idf matrix

pd.DataFrame(
    tfidf_matrix.todense(),
    columns=tfidf.get_feature_names_out(),
    index=anime_unique['name']
).sample(22, axis=1).sample(10, axis=0)

from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import cosine_similarity


# Matriks kesamaan antar anime berdasarkan genre
cosine_sim = cosine_similarity(tfidf_matrix, tfidf_matrix)

cosine_sim

# Membuat dataframe dari variabel cosine_sim dengan baris dan kolom berupa nama judul anime
cosine_sim_df = pd.DataFrame(cosine_sim, index=anime_unique['name'], columns=anime_unique['name'])
print('Shape:', cosine_sim_df.shape)

# Melihat similarity matrix pada setiap judul anime
cosine_sim_df.sample(5, axis=1).sample(10, axis=0)

def Rekomendasi_anime(anime_name, top_n=10):
    match = anime_unique[anime_unique['name'].str.lower() == anime_name.lower()]
    if match.empty:
        return f"Anime '{anime_name}' tidak ditemukan."

    idx = match.index[0]
    pos = anime_unique.index.get_loc(idx)  # Mendapatkan posisi baris untuk cosine_sim

    sim_scores = list(enumerate(cosine_sim[pos]))
    sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)
    sim_scores = sim_scores[1:top_n+1]
    anime_indices = [i[0] for i in sim_scores]

    recommended = anime_unique.iloc[anime_indices]

    return pd.DataFrame({
        'Anime name': recommended['name'].values,
        'Rating': recommended['AverageRating'].values,
        'Genre': recommended['genre'].values
    })

Rekomendasi_anime("Naruto")

"""## Model Development dengan Collaborative Filtering"""

# Definisi model
class RecommenderNet(Model):
    def __init__(self, num_users, num_anime, embedding_size, **kwargs):
        super(RecommenderNet, self).__init__(**kwargs)
        self.user_embedding = layers.Embedding(
            num_users,
            embedding_size,
            embeddings_initializer='he_normal',
            embeddings_regularizer=regularizers.l2(1e-6)
        )
        self.user_bias = layers.Embedding(num_users, 1)
        self.anime_embedding = layers.Embedding(
            num_anime,
            embedding_size,
            embeddings_initializer='he_normal',
            embeddings_regularizer=regularizers.l2(1e-6)
        )
        self.anime_bias = layers.Embedding(num_anime, 1)

    def call(self, inputs):
        user_vector = self.user_embedding(inputs[:, 0])
        user_bias = self.user_bias(inputs[:, 0])
        anime_vector = self.anime_embedding(inputs[:, 1])
        anime_bias = self.anime_bias(inputs[:, 1])

        dot_user_anime = tf.reduce_sum(user_vector * anime_vector, axis=1, keepdims=True)
        x = dot_user_anime + user_bias + anime_bias
        return tf.nn.sigmoid(x)

# Inisialisasi dan compile model
model = RecommenderNet(num_users, num_anime, embedding_size=50)
model.compile(
    loss=tf.keras.losses.BinaryCrossentropy(),
    optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),
    metrics=[tf.keras.metrics.RootMeanSquaredError()]
)

# Training
history = model.fit(
    x=x_train,
    y=y_train,
    batch_size=128,
    epochs=20,
    validation_data=(x_val, y_val)
)

# Rekomendasi anime untuk user tertentu
def recommend_anime_for_user(user_id, anime_rating, top_n=10):
    if user_id not in user_to_user_encoded:
        print(f"User {user_id} tidak ditemukan.")
        return

    user_enc = user_to_user_encoded[user_id]

    anime_watched = anime_rating[anime_rating['user_id'] == user_id]['anime_id'].values
    anime_not_watched = list(set(anime_ids) - set(anime_watched))
    anime_not_watched_encoded = [anime_to_anime_encoded[x] for x in anime_not_watched]

    user_array = np.array([user_enc] * len(anime_not_watched_encoded))
    anime_array = np.array(anime_not_watched_encoded)
    input_array = np.vstack((user_array, anime_array)).T

    pred_ratings = model.predict(input_array).flatten()
    top_indices = pred_ratings.argsort()[-top_n:][::-1]
    top_anime_recommended = [anime_encoded_to_anime[i] for i in anime_array[top_indices]]

    print(f"Rekomendasi anime untuk user {user_id}:")
    for anime_id in top_anime_recommended:
        anime_name = anime_rating[anime_rating['anime_id'] == anime_id]['name'].iloc[0]
        print(f"{anime_name} (ID: {anime_id})")

# Contoh pemakaian
recommend_anime_for_user(user_id=12345, anime_rating=filt_anime_rating, top_n=10)

"""# Evaluasi

## Evaluasi Model CBF
"""

def genre_precision_at_k(query_anime_name, k=10):
    # Ambil genre dari anime yang dijadikan query
    query_row = anime_unique[anime_unique['name'].str.lower() == query_anime_name.lower()]
    if query_row.empty:
        return None  # anime tidak ditemukan
    query_genres = set(query_row['genre'].values[0].split(', '))

    # Ambil rekomendasi berdasarkan genre
    recommended_df = Rekomendasi_anime(query_anime_name, top_n=k)
    if isinstance(recommended_df, str):
        return None  # handle error string return

    matched = 0
    for genre_str in recommended_df['Genre']:
        recommended_genres = set(genre_str.split(', '))
        if query_genres & recommended_genres:  # jika ada overlap genre
            matched += 1

    return matched / k  # precision@k genre

def precision_recall_f1_at_k(user_id, k=10):
    # Ambil anime yang pernah ditonton user
    user_data = anime_rating[anime_rating['user_id'] == user_id]
    relevant_anime = user_data[user_data['rating_user'] >= 7]['anime_id'].values
    relevant_set = set(relevant_anime)

    if len(relevant_set) == 0:
        return None, None, None  # Tidak bisa evaluasi user tanpa data relevan

    # Pilih satu anime dari user tersebut sebagai "query"
    query_anime_id = relevant_anime[0]
    query_anime_name = anime_unique[anime_unique['anime_id'] == query_anime_id]['name'].values[0]

    # Rekomendasi dari CBF
    recommended_df = Rekomendasi_anime(query_anime_name, top_n=k)
    recommended_ids = anime_unique[anime_unique['name'].isin(recommended_df['Anime name'])]['anime_id'].values
    recommended_set = set(recommended_ids)

    # Hitung Precision@K, Recall@K, F1@K
    true_positive = len(recommended_set & relevant_set)
    precision = true_positive / k
    recall = true_positive / len(relevant_set)
    f1 = 2 * precision * recall / (precision + recall) if (precision + recall) > 0 else 0.0

    return precision, recall, f1

sample_titles = anime_unique['name'].sample(20, random_state=42).tolist()

genre_precisions = []

for title in sample_titles:
    precision = genre_precision_at_k(title, k=10)
    if precision is not None:
        genre_precisions.append(precision)

print(f"Average Genre Precision@K: {np.mean(genre_precisions):.4f}")

user_ids_sample = anime_rating['user_id'].drop_duplicates().sample(100, random_state=42)

precision_list = []
recall_list = []
f1_list = []

for user_id in user_ids_sample:
    precision, recall, f1 = precision_recall_f1_at_k(user_id, k=10)
    if precision is not None:
        precision_list.append(precision)
        recall_list.append(recall)
        f1_list.append(f1)

# Rata-rata hasil evaluasi
print(f"Average Precision@K: {np.mean(precision_list):.4f}")
print(f"Average Recall@K: {np.mean(recall_list):.4f}")
print(f"Average F1@K: {np.mean(f1_list):.4f}")

"""Sistem rekomendasi menunjukkan kesesuaian genre yang sangat baik (Precision genre = 1.0), yang berarti sistem berhasil merekomendasikan anime-anime dengan genre yang mirip. Namun, tingkat relevansi berdasarkan rating pengguna masih rendah (Precision@10 < 0.05), mengindikasikan bahwa meskipun genre-nya cocok, belum tentu rekomendasinya dianggap relevan atau menarik oleh pengguna. Ini membuka peluang untuk perbaikan lebih lanjut, misalnya menggabungkan CBF dengan data interaksi pengguna (hybrid model).

## Evaluasi Model CF
"""

# Visualisasi
plt.plot(history.history['root_mean_squared_error'], label='train')
plt.plot(history.history['val_root_mean_squared_error'], label='val')
plt.xlabel('Epoch')
plt.ylabel('RMSE')
plt.legend()
plt.show()

from sklearn.metrics import mean_squared_error, mean_absolute_error
import numpy as np

# Prediksi rating pada data validasi
y_pred = model.predict(x_val).flatten()

# Hitung RMSE dan MAE
rmse = np.sqrt(mean_squared_error(y_val, y_pred))
mae = mean_absolute_error(y_val, y_pred)

print(f"RMSE pada data validasi: {rmse:.4f}")
print(f"MAE pada data validasi: {mae:.4f}")

"""Nilai RMSE dan MAE yang relatif kecil ini menunjukkan model mampu memprediksi rating dengan tingkat akurasi yang baik. Model dapat memahami preferensi pengguna dan memberikan rekomendasi anime yang sesuai dengan minat mereka."""